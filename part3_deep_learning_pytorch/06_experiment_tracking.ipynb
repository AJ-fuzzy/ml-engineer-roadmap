{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Local Experiment Tracking (No External Services)\n",
        "\n",
        "## Objective\n",
        "This notebook demonstrates how to track deep learning experiments locally\n",
        "\n",
        "We log:\n",
        "- Hyperparameters\n",
        "- Training and validation metrics\n",
        "- Model artifacts\n",
        "\n",
        "We are logging this for later comparison. This mirrors what tools like MLflow or W&B automate.\n",
        "\n",
        "(W&B unresolved issues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "1f7024ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import csv\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "39966aa2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "3868c5d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_CONFIG = {\n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 5,\n",
        "    \"num_workers\": 2\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "d7eec33c",
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "d469b158",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(train_dataset, range(5000))\n",
        "test_dataset = torch.utils.data.Subset(test_dataset, range(1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "0522a429",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BASE_CONFIG[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=BASE_CONFIG[\"num_workers\"]\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BASE_CONFIG[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    num_workers=BASE_CONFIG[\"num_workers\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "4bf09011",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64 * 8 * 8, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "6258ced3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return total_loss / len(loader), correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "1ef1453d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return total_loss / len(loader), correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "dd40f117",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment(config, run_name):\n",
        "    model = SimpleCNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        train_loss, train_acc = train_epoch(\n",
        "            model, train_loader, criterion, optimizer, device\n",
        "        )\n",
        "        val_loss, val_acc = evaluate(\n",
        "            model, test_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        results.append([epoch, train_loss, train_acc, val_acc])\n",
        "\n",
        "        print(\n",
        "            f\"{run_name} | Epoch {epoch+1} | \"\n",
        "            f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "09ba0c9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiments = [\n",
        "    {\"lr\": 1e-3, \"epochs\": 5},\n",
        "    {\"lr\": 1e-4, \"epochs\": 5}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "af791a66",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run_0 | Epoch 1 | Train Acc: 0.2996 | Val Acc: 0.3810\n",
            "run_0 | Epoch 2 | Train Acc: 0.4432 | Val Acc: 0.4610\n",
            "run_0 | Epoch 3 | Train Acc: 0.5032 | Val Acc: 0.4610\n",
            "run_0 | Epoch 4 | Train Acc: 0.5562 | Val Acc: 0.5070\n",
            "run_0 | Epoch 5 | Train Acc: 0.6020 | Val Acc: 0.5550\n",
            "run_1 | Epoch 1 | Train Acc: 0.2372 | Val Acc: 0.2870\n",
            "run_1 | Epoch 2 | Train Acc: 0.3230 | Val Acc: 0.3680\n",
            "run_1 | Epoch 3 | Train Acc: 0.3726 | Val Acc: 0.3710\n",
            "run_1 | Epoch 4 | Train Acc: 0.4010 | Val Acc: 0.4150\n",
            "run_1 | Epoch 5 | Train Acc: 0.4326 | Val Acc: 0.4360\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "\n",
        "for i, exp in enumerate(experiments):\n",
        "    config = {**BASE_CONFIG, **exp}\n",
        "    results = run_experiment(config, run_name=f\"run_{i}\")\n",
        "\n",
        "    with open(f\"logs/run_{i}.csv\", \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"epoch\", \"train_loss\", \"train_acc\", \"val_acc\"])\n",
        "        writer.writerows(results)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mldm2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
